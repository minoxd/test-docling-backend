{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### python api tryout",
   "id": "c255825afcef02a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### base",
   "id": "7bd8a6e0e70c5083"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.355006Z",
     "start_time": "2025-09-05T09:01:17.113088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import logging\n",
    "import pprint\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.document import ConversionResult\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling_core.transforms.chunker import BaseChunk, DocChunk\n",
    "from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n",
    "from docling_core.types import DoclingDocument\n",
    "from docling_core.types.doc import ImageRefMode, RefItem, DocItem, NodeItem, ProvenanceItem, BoundingBox, PictureItem\n",
    "from dotenv import dotenv_values"
   ],
   "id": "560ccffc5d6cc77",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.373574Z",
     "start_time": "2025-09-05T09:01:24.370873Z"
    }
   },
   "cell_type": "code",
   "source": "_logger = logging.getLogger(__name__)",
   "id": "b107ffe71a0c6fd1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.383900Z",
     "start_time": "2025-09-05T09:01:24.380639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_converter():\n",
    "    pipeline_options = PdfPipelineOptions(\n",
    "        generate_picture_images=True,  # Generate base64-encoded images\n",
    "        # do_picture_classification=True, # Classify images (optional, but aligns with CLI)\n",
    "        images_scale=3.0,\n",
    "    )\n",
    "\n",
    "    converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "    return converter"
   ],
   "id": "700793ec5efef87b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.394573Z",
     "start_time": "2025-09-05T09:01:24.391759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_chunker():\n",
    "    chunker = HybridChunker()\n",
    "    return chunker"
   ],
   "id": "3f1f863937a01207",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.407780Z",
     "start_time": "2025-09-05T09:01:24.404884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyNode(object):\n",
    "    cref_original: str\n",
    "    cref_new: str\n",
    "\n",
    "    def __init__(self, cref_original):\n",
    "        self.cref_original = cref_original\n",
    "        self.parent = None\n",
    "        self.children = []\n",
    "\n",
    "    # def __str__(self):\n",
    "    #     return self.title\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.cref_original\n",
    "\n",
    "    # depth first search\n",
    "    def __iter__(self):\n",
    "        yield self\n",
    "        for child in self.children:\n",
    "            for node in child:\n",
    "                yield node"
   ],
   "id": "2b0404750f1a7cff",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.416761Z",
     "start_time": "2025-09-05T09:01:24.413408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def construct_chunk_tree(chunks: list[BaseChunk], tree_title: str = 'root'):\n",
    "    tree = MyNode(tree_title)\n",
    "    node_dict = {tree_title: tree}\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk_json_dict = chunk.export_json_dict()\n",
    "        headings = [tree_title]\n",
    "        headings.extend(chunk_json_dict['meta']['headings'])\n",
    "\n",
    "        for heading in headings:\n",
    "            if heading not in node_dict:\n",
    "                node_dict[heading] = MyNode(heading)\n",
    "\n",
    "        while len(headings) >= 2:\n",
    "            node = node_dict[headings[0]]\n",
    "            child_node = node_dict[headings[1]]\n",
    "            if child_node not in node.children:\n",
    "                node.children.append(child_node)\n",
    "            headings.pop(0)\n",
    "\n",
    "    return tree"
   ],
   "id": "3a429cb806c1fe52",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.425404Z",
     "start_time": "2025-09-05T09:01:24.422554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_as_html(result: ConversionResult, filename: str, image_mode: ImageRefMode, save_dir: str = 'saves'):\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(exist_ok=True)\n",
    "    filename = Path(save_dir, filename).with_suffix(\".html\")\n",
    "\n",
    "    artifacts_dir = filename.with_suffix(\"\")\n",
    "    artifacts_dir = artifacts_dir.with_name(artifacts_dir.name + \"_artifacts\")\n",
    "\n",
    "    result.document.save_as_html(filename=filename, artifacts_dir=artifacts_dir, image_mode=image_mode)\n",
    "\n",
    "    return filename, artifacts_dir"
   ],
   "id": "33a5884a4ed72991",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.434277Z",
     "start_time": "2025-09-05T09:01:24.430874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_exported_content(soup: BeautifulSoup):\n",
    "    children_of_body = soup.body.find_all(name=True, recursive=False)\n",
    "\n",
    "    if len(children_of_body) != 1:\n",
    "        raise Exception(f'eyyo {len(children_of_body)} children in body. Expected only body_content')\n",
    "\n",
    "    body_content = children_of_body[0]\n",
    "    body_content = body_content.find_all(name=True, recursive=False)\n",
    "    return body_content"
   ],
   "id": "c98c9a3649a981fb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.442500Z",
     "start_time": "2025-09-05T09:01:24.439545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def upload_image(artifact: Path, imgbb_api_key: str):\n",
    "    \"\"\"\n",
    "    upload one\n",
    "    \"\"\"\n",
    "    url = \"https://api.imgbb.com/1/upload\"\n",
    "    params = {\n",
    "        # \"expiration\": 600,  # what is this\n",
    "        \"key\": imgbb_api_key,\n",
    "    }\n",
    "    try:\n",
    "        with open(artifact, 'rb') as f:\n",
    "            files = {\n",
    "                'image': f\n",
    "            }\n",
    "            response = requests.post(url, params=params, files=files)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(\"Upload successful!\")\n",
    "            print(response.json())\n",
    "            return response.json()['data']['url']\n",
    "        else:\n",
    "            raise Exception(f\"Upload failed with status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(e, response.text)"
   ],
   "id": "c45ea4c875c35fad",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.451237Z",
     "start_time": "2025-09-05T09:01:24.447752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def upload_images(body_content: list[Tag], artifacts_dir: Path, config: dict):\n",
    "    figures = []\n",
    "    for child in body_content:\n",
    "        if child.name == 'figure':\n",
    "            child_of_child = child.find_all(name=True, recursive=False)\n",
    "            if len(child_of_child) == 1 and child_of_child[0].name == 'img':\n",
    "                figures.append(child)\n",
    "\n",
    "    artifacts = list(artifacts_dir.glob('*.png'))\n",
    "\n",
    "    for figure, artifact in zip(figures, artifacts):\n",
    "        img = figure.find_all(name=True, recursive=False)[0]\n",
    "        img_path = Path(artifact.parent.parent, unquote(img['src']))\n",
    "\n",
    "        # validate 2 ways of manually get image reference\n",
    "        if img_path != artifact:\n",
    "            raise Exception(f'paths unmatched. \\n{img_path}\\n{artifact}')\n",
    "\n",
    "    for figure, artifact in zip(figures, artifacts):\n",
    "        img_url = await upload_image(artifact, imgbb_api_key=config['IMGBB_API_KEY'])\n",
    "\n",
    "        img = figure.find_all(name=True, recursive=False)[0]\n",
    "        img['src'] = img_url"
   ],
   "id": "db87eec6425eaa73",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:01:24.459633Z",
     "start_time": "2025-09-05T09:01:24.456612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_output(body_content: list[Tag], chunk_tree: MyNode):\n",
    "    indexes_chunk_begin = []\n",
    "    chunks_headings = [str(chunk) for chunk in chunk_tree]\n",
    "    chunks_headings.pop(0)\n",
    "    for idx, child in enumerate(body_content):\n",
    "        if 'h' not in child.name:\n",
    "            continue\n",
    "        if child.string in chunks_headings:\n",
    "            indexes_chunk_begin.append(idx)\n",
    "            chunks_headings.pop(0)\n",
    "    indexes_chunk_begin.append(len(body_content))\n",
    "    print(chunks_headings)\n",
    "    print(indexes_chunk_begin)\n",
    "    html_chunks = []\n",
    "    for idx in range(len(indexes_chunk_begin) - 1):\n",
    "        print(body_content[indexes_chunk_begin[idx]:indexes_chunk_begin[idx + 1]])\n",
    "        html_chunks.append(\n",
    "            ''.join([str(child) for child in body_content[indexes_chunk_begin[idx]:indexes_chunk_begin[idx + 1]]]))\n",
    "\n",
    "    return html_chunks # output tree also"
   ],
   "id": "bebfd7ce4c88cef0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### test",
   "id": "f290c289650c534d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:05:41.071392Z",
     "start_time": "2025-09-05T09:05:33.681494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# o_source = \"input/2025 ICT Bachelor thesis template.docx\"\n",
    "o_source = \"input/Flower-Parts-Diagrams.pdf\"\n",
    "# o_source = \"input/Protein and Nucleic Acid.docx\"\n",
    "o_converter = create_converter()\n",
    "o_result = o_converter.convert(o_source)\n",
    "o_document = o_result.document\n",
    "o_chunker = create_chunker()\n",
    "\n",
    "o_chunk_iter = o_chunker.chunk(o_document)\n",
    "o_chunks = list(o_chunk_iter)"
   ],
   "id": "c7c6ea6d9dae6700",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "o_chunk_tree = construct_chunk_tree(o_chunks)\n",
    "\n",
    "o_filename: str = 'o_my_raw' #todo\n",
    "o_save_results: tuple[Path, Path,] = save_as_html(result=o_result, filename=o_filename,\n",
    "                                                image_mode=ImageRefMode.REFERENCED)\n",
    "o_filename, o_artifacts_dir = o_save_results\n",
    "\n",
    "with open(o_filename, encoding='utf-8') as o_f:\n",
    "    o_soup = BeautifulSoup(''.join([o_line.strip() for o_line in o_f.readlines()]), 'html.parser')\n",
    "\n",
    "o_body_content = extract_exported_content(o_soup)\n",
    "\n",
    "o_config = dotenv_values()\n",
    "\n",
    "# await upload_images(body_content=o_body_content, artifacts_dir=o_artifacts_dir, config=o_config)\n",
    "\n",
    "o_html_chunks = generate_output(body_content=o_body_content, chunk_tree=o_chunk_tree)"
   ],
   "id": "8b0869b725f45354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:42:01.307361Z",
     "start_time": "2025-08-28T08:42:01.298745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_list(l: list):\n",
    "    for i, e in enumerate(l):\n",
    "        print(f'{\"-\"*30}{i}{\"-\"*30}')\n",
    "        # pprint.pprint(e.export_json_dict()['meta'].keys(), sort_dicts=False)\n",
    "        pprint.pprint(e.export_json_dict(), sort_dicts=False)\n",
    "\n",
    "print_list(o_chunks)"
   ],
   "id": "b2e98edf9ac9c649",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------0------------------------------\n",
      "{'text': 'Wild Geranium, Geranium maculatum',\n",
      " 'meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta',\n",
      "          'version': '1.0.0',\n",
      "          'doc_items': [{'self_ref': '#/texts/1',\n",
      "                         'parent': {'$ref': '#/body'},\n",
      "                         'children': [],\n",
      "                         'content_layer': 'body',\n",
      "                         'label': 'text',\n",
      "                         'prov': [{'page_no': 1,\n",
      "                                   'bbox': {'l': 133.81,\n",
      "                                            't': 652.428,\n",
      "                                            'r': 412.182,\n",
      "                                            'b': 632.897,\n",
      "                                            'coord_origin': 'BOTTOMLEFT'},\n",
      "                                   'charspan': [0, 33]}]}],\n",
      "          'headings': ['Parts of a Simple Flower'],\n",
      "          'origin': {'mimetype': 'application/pdf',\n",
      "                     'binary_hash': 4392405294199241303,\n",
      "                     'filename': 'Flower-Parts-Diagrams.pdf'}}}\n",
      "------------------------------1------------------------------\n",
      "{'text': '- Sepals -The outermost part of the flower, often green but '\n",
      "         'sometimes looking like petals, that usually enclose the flower bud '\n",
      "         'before it opens.\\n'\n",
      "         '- Petals - The inner ring of the flower that tend to be brightly '\n",
      "         'colored and often function to attract pollinators.\\n'\n",
      "         '- Stamen - The male part of the flower that serves to produce '\n",
      "         'pollen; it is composed of the pollen-bearing anther and the '\n",
      "         'stalk-like filament.\\n'\n",
      "         '- Pistil The female part of the flower that typically consists of '\n",
      "         'the stigma at the top which receives the pollen, the narrow style , '\n",
      "         'and the ovary which contains ovules that will later develop into '\n",
      "         'seeds.',\n",
      " 'meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta',\n",
      "          'version': '1.0.0',\n",
      "          'doc_items': [{'self_ref': '#/texts/14',\n",
      "                         'parent': {'$ref': '#/groups/0'},\n",
      "                         'children': [],\n",
      "                         'content_layer': 'body',\n",
      "                         'label': 'list_item',\n",
      "                         'prov': [{'page_no': 1,\n",
      "                                   'bbox': {'l': 46.792,\n",
      "                                            't': 187.764,\n",
      "                                            'r': 493.257,\n",
      "                                            'b': 155.53300000000002,\n",
      "                                            'coord_origin': 'BOTTOMLEFT'},\n",
      "                                   'charspan': [0, 141]}]},\n",
      "                        {'self_ref': '#/texts/15',\n",
      "                         'parent': {'$ref': '#/groups/0'},\n",
      "                         'children': [],\n",
      "                         'content_layer': 'body',\n",
      "                         'label': 'list_item',\n",
      "                         'prov': [{'page_no': 1,\n",
      "                                   'bbox': {'l': 46.792,\n",
      "                                            't': 154.644,\n",
      "                                            'r': 496.681,\n",
      "                                            'b': 122.41300000000001,\n",
      "                                            'coord_origin': 'BOTTOMLEFT'},\n",
      "                                   'charspan': [0, 113]}]},\n",
      "                        {'self_ref': '#/texts/16',\n",
      "                         'parent': {'$ref': '#/groups/0'},\n",
      "                         'children': [],\n",
      "                         'content_layer': 'body',\n",
      "                         'label': 'list_item',\n",
      "                         'prov': [{'page_no': 1,\n",
      "                                   'bbox': {'l': 46.792,\n",
      "                                            't': 120.56399999999996,\n",
      "                                            'r': 474.184,\n",
      "                                            'b': 88.57299999999998,\n",
      "                                            'coord_origin': 'BOTTOMLEFT'},\n",
      "                                   'charspan': [0, 140]}]},\n",
      "                        {'self_ref': '#/texts/17',\n",
      "                         'parent': {'$ref': '#/groups/0'},\n",
      "                         'children': [],\n",
      "                         'content_layer': 'body',\n",
      "                         'label': 'list_item',\n",
      "                         'prov': [{'page_no': 1,\n",
      "                                   'bbox': {'l': 46.792,\n",
      "                                            't': 86.72400000000005,\n",
      "                                            'r': 486.021,\n",
      "                                            'b': 38.41300000000001,\n",
      "                                            'coord_origin': 'BOTTOMLEFT'},\n",
      "                                   'charspan': [0, 203]}]}],\n",
      "          'headings': ['Definitions:'],\n",
      "          'origin': {'mimetype': 'application/pdf',\n",
      "                     'binary_hash': 4392405294199241303,\n",
      "                     'filename': 'Flower-Parts-Diagrams.pdf'}}}\n",
      "------------------------------2------------------------------\n",
      "{'text': 'Green and Gold, Chrysogonum virginianum',\n",
      " 'meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta',\n",
      "          'version': '1.0.0',\n",
      "          'doc_items': [{'self_ref': '#/texts/19',\n",
      "                         'parent': {'$ref': '#/body'},\n",
      "                         'children': [],\n",
      "                         'content_layer': 'body',\n",
      "                         'label': 'text',\n",
      "                         'prov': [{'page_no': 2,\n",
      "                                   'bbox': {'l': 115.32,\n",
      "                                            't': 656.268,\n",
      "                                            'r': 430.728,\n",
      "                                            'b': 636.737,\n",
      "                                            'coord_origin': 'BOTTOMLEFT'},\n",
      "                                   'charspan': [0, 39]}]}],\n",
      "          'headings': ['Parts of a Composite Flower'],\n",
      "          'origin': {'mimetype': 'application/pdf',\n",
      "                     'binary_hash': 4392405294199241303,\n",
      "                     'filename': 'Flower-Parts-Diagrams.pdf'}}}\n",
      "------------------------------3------------------------------\n",
      "{'text': 'Composite flowers can be made of all ray flowers that look like the '\n",
      "         \"petals of a 'normal' flower (e.g. dandelions), all small knobby disk \"\n",
      "         'flowers (e.g. thistles), or both types (like this one, Green and '\n",
      "         'Gold). The single petal on a ray flower is called a ligule . On both '\n",
      "         'ray and disk flowers, the pollen-producing anthers are typically '\n",
      "         'fused together into a tube; on a disk flower, the petals are also '\n",
      "         'typically fused. The pistil , commonly with two curling lobes, '\n",
      "         'emerges as each disk or ray flower matures. In Green and Gold, the '\n",
      "         'ray flowers are lacking stamens (pistillate).',\n",
      " 'meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta',\n",
      "          'version': '1.0.0',\n",
      "          'doc_items': [{'self_ref': '#/texts/30',\n",
      "                         'parent': {'$ref': '#/body'},\n",
      "                         'children': [],\n",
      "                         'content_layer': 'body',\n",
      "                         'label': 'text',\n",
      "                         'prov': [{'page_no': 2,\n",
      "                                   'bbox': {'l': 46.492,\n",
      "                                            't': 161.12400000000002,\n",
      "                                            'r': 499.3,\n",
      "                                            'b': 29.65599999999995,\n",
      "                                            'coord_origin': 'BOTTOMLEFT'},\n",
      "                                   'charspan': [0, 577]}]}],\n",
      "          'headings': ['Notes:'],\n",
      "          'origin': {'mimetype': 'application/pdf',\n",
      "                     'binary_hash': 4392405294199241303,\n",
      "                     'filename': 'Flower-Parts-Diagrams.pdf'}}}\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:33.682767Z",
     "start_time": "2025-09-05T09:04:33.678523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def register_node_bottom_up(\n",
    "        node_item: NodeItem,  # current NodeItem\n",
    "        cref_to_my_node: dict[str, MyNode],  # dict of ref to MyNode\n",
    "        dldoc_original: DoclingDocument\n",
    "):\n",
    "    self_cref: str = node_item.get_ref().cref\n",
    "    parent_cref: str = getattr(node_item.parent, 'cref', '_root_')\n",
    "\n",
    "    if parent_cref not in cref_to_my_node:\n",
    "        cref_to_my_node[parent_cref] = MyNode(parent_cref)\n",
    "    if self_cref not in cref_to_my_node:\n",
    "        cref_to_my_node[self_cref] = MyNode(self_cref)\n",
    "    cref_to_my_node[self_cref].parent = cref_to_my_node[parent_cref]\n",
    "    if cref_to_my_node[self_cref] not in cref_to_my_node[parent_cref].children:\n",
    "        cref_to_my_node[parent_cref].children.append(cref_to_my_node[self_cref])\n",
    "\n",
    "    if parent_cref != '_root_':\n",
    "        node_item = node_item.parent.resolve(dldoc_original)\n",
    "        register_node_bottom_up(node_item, cref_to_my_node, dldoc_original)\n",
    "\n",
    "\n",
    "def register_node_top_down(\n",
    "        node_item: NodeItem,  # current NodeItem\n",
    "        cref_to_my_node: dict[str, MyNode],  # dict of ref to MyNode\n",
    "        dldoc_original: DoclingDocument\n",
    "):\n",
    "    self_cref: str = node_item.get_ref().cref\n",
    "    children_ref_items: list[RefItem] = copy.deepcopy(node_item.children)\n",
    "\n",
    "    while len(children_ref_items) > 0:\n",
    "        child_ref_item = children_ref_items.pop(0)\n",
    "        child_cref = child_ref_item.cref\n",
    "        child_item = child_ref_item.resolve(dldoc_original)\n",
    "\n",
    "        cref_to_my_node[child_cref] = MyNode(child_cref)\n",
    "        cref_to_my_node[child_cref].parent = cref_to_my_node[self_cref]\n",
    "        cref_to_my_node[self_cref].children.append(cref_to_my_node[child_cref])\n",
    "        if child_item.children:\n",
    "            register_node_top_down(child_item, cref_to_my_node, dldoc_original)"
   ],
   "id": "307cd7c99080e591",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:34.126151Z",
     "start_time": "2025-09-05T09:04:34.122642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo rename to convert_doc_items_to_dldoc\n",
    "def convert_chunk_to_doc(chunk: DocChunk, dldoc_original: DoclingDocument):\n",
    "    dldoc_new = DoclingDocument(name=dldoc_original.name)\n",
    "    doc_items: list[DocItem] = chunk.meta.doc_items\n",
    "\n",
    "    # construct a tree of custom nodes represent the NodeItem used in the chunk, furtherly used to add NodeItem into new doc\n",
    "    cref_to_my_node: dict[str, MyNode] = {}\n",
    "\n",
    "    # note that doc_items are indexed by the order of their appearance in the original document\n",
    "    for doc_item in doc_items:\n",
    "        node_item = doc_item.get_ref().resolve(dldoc_original)\n",
    "\n",
    "        register_node_bottom_up(node_item, cref_to_my_node, dldoc_original)\n",
    "        if doc_item.children:\n",
    "            register_node_top_down(node_item, cref_to_my_node, dldoc_original)\n",
    "\n",
    "    ordered_my_node = [node for node in cref_to_my_node['_root_']]\n",
    "\n",
    "    # iterate using DFS, meaning nodes will be added in top-down order\n",
    "    for my_node in ordered_my_node[1:]:\n",
    "        # deepcopy is used so that child refs deletion will not affect the original object\n",
    "        item_in_dldoc_original = copy.deepcopy(RefItem(cref=my_node.cref_original).resolve(dldoc_original))  # type: ignore\n",
    "        item_in_dldoc_original.children.clear()\n",
    "        self_path = my_node.cref_original.split('/')\n",
    "        item_label = self_path[1]\n",
    "\n",
    "        # parent items are guaranteed to be added before\n",
    "        parent_item_in_dldoc_new = None if my_node.parent.cref_original == '_root_' else RefItem(cref=my_node.parent.cref_new).resolve(dldoc_new)  # type: ignore\n",
    "        dldoc_new.append_child_item(child=item_in_dldoc_original, parent=parent_item_in_dldoc_new)\n",
    "\n",
    "        my_node.cref_new = dldoc_new.__getattribute__(item_label)[-1].get_ref().cref if parent_item_in_dldoc_new else my_node.cref_original\n",
    "    return dldoc_new"
   ],
   "id": "2071c2bd84825f16",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:34.417217Z",
     "start_time": "2025-09-05T09:04:34.414565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_chunk_bboxes(chunk_bboxes):\n",
    "    for i in range(1, len(chunk_bboxes)):\n",
    "        prev_bbox = chunk_bboxes[i - 1]\n",
    "        curr_bbox = chunk_bboxes[i]\n",
    "        if curr_bbox[1] > prev_bbox[3]:\n",
    "            return False\n",
    "    return True"
   ],
   "id": "65338616e36b361e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:34.745267Z",
     "start_time": "2025-09-05T09:04:34.741290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_picture_position(chunk_bboxes_by_page_no: dict[int, list[tuple[float, float, float, float]]], picture: PictureItem):\n",
    "    prov_list: list[ProvenanceItem] = picture.prov\n",
    "    if len(prov_list) != 1:\n",
    "        raise Exception(f'eyyo {len(prov_list)} provenance in picture.prov')\n",
    "    prov: ProvenanceItem = prov_list[0]\n",
    "    page_no: int = prov.page_no\n",
    "    bbox: BoundingBox = prov.bbox\n",
    "    l, t, r, b = bbox.l, bbox.t, bbox.r, bbox.b\n",
    "    pos: int = 0\n",
    "    not_found: bool = True\n",
    "    while not_found and pos <= len(chunk_bboxes_by_page_no[page_no]):\n",
    "        chunk_bboxes_of_page = copy.deepcopy(chunk_bboxes_by_page_no[page_no])\n",
    "        chunk_bboxes_of_page.insert(pos, (l, t, r, b))\n",
    "\n",
    "        if validate_chunk_bboxes(chunk_bboxes_of_page):\n",
    "            not_found = False\n",
    "        else:\n",
    "            pos += 1\n",
    "    if not_found:\n",
    "        raise Exception(f'eyyo can not fit picture')\n",
    "    return page_no, pos"
   ],
   "id": "eb7fb4f38f7e46a3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:35.007854Z",
     "start_time": "2025-09-05T09:04:35.004697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_chunk_bbox(chunk_idx: int, chunk: DocChunk):\n",
    "    doc_items: list[DocItem] = chunk.meta.doc_items\n",
    "    page_no = None\n",
    "    l: float  = sys.maxsize  # left\n",
    "    t: float  = - sys.maxsize  # top\n",
    "    r: float  = - sys.maxsize  # right\n",
    "    b: float  = sys.maxsize  # bottom\n",
    "\n",
    "    for doc_item_idx, doc_item in enumerate(doc_items):\n",
    "        prov_list: list[ProvenanceItem] = doc_item.prov\n",
    "        if len(prov_list) != 1:\n",
    "            if len(prov_list) == 0:\n",
    "                _logger.warning(\n",
    "                    f'hmm no prov in chunk {chunk_idx}, doc_item {doc_item_idx}'\n",
    "                )\n",
    "                continue\n",
    "            raise Exception(f'eyyo {len(prov_list)} provenance in doc_item.prov')\n",
    "        prov: ProvenanceItem = prov_list[0]\n",
    "        if page_no is not None and page_no != prov.page_no:\n",
    "            raise Exception(f'eyyo page_no mismatch')\n",
    "        page_no = prov.page_no\n",
    "        bbox: BoundingBox = prov.bbox\n",
    "        l = min(l, bbox.l)\n",
    "        t = max(t, bbox.t)\n",
    "        r = max(r, bbox.r)\n",
    "        b = min(b, bbox.b)\n",
    "\n",
    "    return page_no, l, t, r, b"
   ],
   "id": "4fa634f881998d83",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:35.298592Z",
     "start_time": "2025-09-05T09:04:35.295227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_source_format(document: DoclingDocument):\n",
    "    \"\"\"\n",
    "    simple function to get the format of the source. Refactor to use the DoclingDocument object later.\n",
    "    \"\"\"\n",
    "    source = document.origin.filename\n",
    "    if source.endswith('.docx'):\n",
    "        source_format = 'docx'\n",
    "    elif source.endswith('.pdf'):\n",
    "        source_format = 'pdf'\n",
    "    else:\n",
    "        raise Exception(f'eyyo unknown source format')\n",
    "    return source_format"
   ],
   "id": "58f57821e9b9a65a",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:35.934980Z",
     "start_time": "2025-09-05T09:04:35.932710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_picture_to_chunk_if_docx(chunks_original: list[DocChunk], document: DoclingDocument):\n",
    "    return chunks_original"
   ],
   "id": "e8d30bf7454929d4",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:36.394970Z",
     "start_time": "2025-09-05T09:04:36.390729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_picture_to_chunk_if_pdf(chunks_original: list[DocChunk], document: DoclingDocument):\n",
    "    \"\"\"\n",
    "    This function modifies chunks, so chunks will be deepcopy-ed so that changes won't affect the original chunks. This means this function can be used multiple times on one unmodifiable list of chunks.\n",
    "    \"\"\"\n",
    "    chunks = copy.deepcopy(chunks_original)\n",
    "    chunk_bboxes: list[tuple[int, float, float, float, float]] = [get_chunk_bbox(idx, chunk) for idx, chunk in enumerate(chunks)]\n",
    "    chunk_bboxes_by_page_no: dict[int, list[tuple[float, float, float, float]]] = {\n",
    "        page_no: [] for page_no in document.pages.keys()\n",
    "    }\n",
    "    for chunk_bbox in chunk_bboxes:\n",
    "        page_no, l, t, r, b = chunk_bbox\n",
    "        if not page_no:\n",
    "            continue\n",
    "        chunk_bboxes_by_page_no[page_no].append((l, t, r, b))\n",
    "\n",
    "    pictures: list[PictureItem] = document.pictures\n",
    "    for picture in pictures:\n",
    "        page_no, pos = find_picture_position(chunk_bboxes_by_page_no, picture)\n",
    "        idx = sum([len(chunk_bboxes_by_page_no[i]) if i != 0 else 0 for i in range(page_no)]) + pos - 1\n",
    "        chunk = chunks[idx]\n",
    "        chunk.meta.doc_items.append(DocItem(\n",
    "            self_ref=picture.self_ref,\n",
    "            parent=picture.parent,\n",
    "            children=picture.children,\n",
    "            content_layer=picture.content_layer,\n",
    "            label=picture.label,\n",
    "            prov=picture.prov\n",
    "        ))\n",
    "\n",
    "    return chunks"
   ],
   "id": "53cfe3b61bec283b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:37.063570Z",
     "start_time": "2025-09-05T09:04:37.059984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_chunks(chunks_original: list[DocChunk], document: DoclingDocument):\n",
    "    chunks: list[DocChunk] = []\n",
    "    match get_source_format(document):\n",
    "        case 'docx':\n",
    "            chunks = add_picture_to_chunk_if_docx(chunks_original, document)\n",
    "        case 'pdf':\n",
    "            chunks = add_picture_to_chunk_if_pdf(chunks_original, document)\n",
    "\n",
    "    docs = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk_as_doc = convert_chunk_to_doc(chunk, document)\n",
    "        chunk_as_doc.save_as_html(f'chunk{idx}.html', image_mode=ImageRefMode.REFERENCED)\n",
    "        docs.append(chunk_as_doc)\n",
    "\n",
    "    return docs"
   ],
   "id": "9af748442ed80af1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:05:41.390215Z",
     "start_time": "2025-09-05T09:05:41.089190Z"
    }
   },
   "cell_type": "code",
   "source": "o_docs: list[DoclingDocument] = process_chunks(o_chunks, o_document)",
   "id": "e57fd0507a4db72a",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T09:04:53.949161Z",
     "start_time": "2025-09-05T09:04:53.755118Z"
    }
   },
   "cell_type": "code",
   "source": "o_document.save_as_html('full.html', image_mode=ImageRefMode.REFERENCED)",
   "id": "dfb3d064ca6d6261",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T08:03:50.328515Z",
     "start_time": "2025-09-03T08:03:50.325774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for o_chunk in o_chunks:\n",
    "    print(get_chunk_bbox(o_chunk))"
   ],
   "id": "5c304f337ad0face",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 133.81, 652.428, 412.182, 632.897)\n",
      "(1, 46.792, 187.764, 496.681, 38.41300000000001)\n",
      "(2, 115.32, 656.268, 430.728, 636.737)\n",
      "(2, 46.492, 161.12400000000002, 499.3, 29.65599999999995)\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for i, chunk in enumerate(o_chunks):\n",
    "#     print(f\"=== {i} ===\")\n",
    "#     print(f\"chunk.text:\\n{f'{chunk.text[:300]}…'!r}\")\n",
    "#\n",
    "#     enriched_text = o_chunker.contextualize(chunk=chunk)\n",
    "#     print(f\"chunker.contextualize(chunk):\\n{f'{enriched_text[:300]}…'!r}\")\n",
    "#\n",
    "#     print()"
   ],
   "id": "aa480e9b411fca38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:08:52.740955Z",
     "start_time": "2025-08-28T09:08:52.738184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "child_item_haha = RefItem(cref='#/pictures/0').resolve(o_document)\n",
    "child_item_haha.children.clear()\n",
    "o_docs[1].append_child_item(child=child_item_haha, parent=RefItem(cref='#/body').resolve(o_docs[1]))"
   ],
   "id": "dac2accc0511458",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:09:05.591078Z",
     "start_time": "2025-08-28T09:09:05.531034Z"
    }
   },
   "cell_type": "code",
   "source": "o_docs[1].save_as_html('chunk1.html', image_mode=ImageRefMode.REFERENCED)",
   "id": "63293b4e2bb8c4ee",
   "outputs": [],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
